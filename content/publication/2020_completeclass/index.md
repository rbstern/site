---
abstract: We examine general decision problems with loss functions that are bounded below. We allow the loss function to assume the value infinity. No other assumptions are made about the action space, the types of data available, the types of non-randomized decision rules allowed, or the parameter space. By allowing prior distributions and the randomizations in randomized rules to be finitely-additive, we prove very general complete class and minimax theorems. Specifically, under the sole assumption that the loss function is bounded below, we show that every decision problem has a minimal complete class and all admissible rules are Bayes rules. We also show that every decision problem has a minimax rule and a least-favorable distribution and that every minimax rule is Bayes with respect to the least-favorable distribution. Some special care is required to deal properly with infinite-valued risk functions and integrals taking infinite values.

authors:
- Mark J. Schervish
- Teddy Seidenfeld
- admin
- Joseph B. Kadane
date: "2021-08-22T00:00:00Z"
doi: "10.1007/s10260-019-00486-6"
featured: false
image:
  caption: ''
  focal_point: ""
  preview_only: false
publication: In *Statistical Methods & Applications*
publication_short: In *SMA*
publication_types:
- "2"
publishDate: "2020-08-19T00:00:00Z"
project: 
slides: 
summary: We examine general decision problems with loss functions that are bounded below. We allow the loss function to assume the value infinity. No other assumptions are made about the action space, the types of data available, the types of non-randomized decision rules allowed, or the parameter space. By allowing prior distributions and the randomizations in randomized rules to be finitely-additive, we prove very general complete class and minimax theorems. Specifically, under the sole assumption that the loss function is bounded below, we show that every decision problem has a minimal complete class and all admissible rules are Bayes rules. We also show that every decision problem has a minimax rule and a least-favorable distribution and that every minimax rule is Bayes with respect to the least-favorable distribution. Some special care is required to deal properly with infinite-valued risk functions and integrals taking infinite values.
tags: [Foundations, Complete class, Minimax]
title: 'What finite-additivity can add to decision theory'
url_code: ""
url_dataset: ""
url_pdf: "https://link.springer.com/article/10.1007/s10260-019-00486-6"
url_poster: ""
url_project: ""
url_slides: ""
url_source: "https://www.cmu.edu/dietrich/philosophy/docs/seidenfeld/what-finite-additivity-can-add-to-decision-theory.pdf"
url_video: ""
---
